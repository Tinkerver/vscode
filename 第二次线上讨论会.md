- 深度学习得以飞速发展得益于其在多个领域取得突破传统方法的效果
- 深度神经网络模型的“深度”带来“复杂性”哪些困难?
- 可解释性是解释到什么程度，一个深度网络每一个神经元是做什么的。如果解释程度80%，说明在一个数据集上对某一个对象的解释 --张长水清华
- 驱动力是什么，需要解释哪些方面。结构可解释性，特征可解释性，功能可解释性，决策可解释性
- 多任务学习的具体场景，有多个学习任务，有多个神经网络。构成一个深度场景。这个物理场景就是我们需要聚焦解决的。
  - 多任务学习的深度神经网络智能系统
  - 目标:构建多视角多维度的模型可解释理论体系
  - 4个方面的可解释理论:结构解耦的可解释理论，特征关联的可解释理论（三点一致性上散发的可解释性体系（如老师教英语，要教英语本身发音的完备特征。学生无遗漏的学习特征。老师检测时如果考试范围与以上不一致，会出问题。）打标签的特征，学习时学习的特征，检测时使用特征，三者要一致。在网络中，不同卷积核提取到了不同特征，这些特征有什么计算关联性？横向相关性？对于一个识别鸟的任务，如果第一层提取基本的特征，如鸟头，翅膀，第二层确定时鹦鹉，关注鹦鹉子类的相关特征。第三层靠脚趾的弯曲来区分子类的子类。在纵向和横向上都可能有关联特征。 还有针对过滤器的可解释性，如果把过滤器的操作映射到人的语义，是否存在相应关联），功能组合的可解释理论，决策与度量的可解释理论+典型的应用验证场景

DL需要解释哪些方面?
(DL网络模型结构的可解释性)
- 从数据、模型到决策，DL是如何得出这个结论的? 
- (DL网络模型结构的可解释性)区
  - DL网络模型结构解耦的通用框
  - 过滤器的语义定义机制及其可解释性，基于逐步迭代方法的神经元语义聚族机制中
  - DL网络模型结构的语义表征方法
  - DL网络模型结构的人能理解的语义映射机制与度量方法
  - DL网络模型结构复杂性与决策度量模型的关系

DL需要解释哪些方面?
- 从数据、模型到决策，同样的训练数据，为什么在不同的学习模型会得到不同结论?不同结构模型的特征提取方法不同、特征分布情况不同、特征层间转换方法不同、决策模型的计算方法不同等等(DL网络模型的特征提取、分布与转换方法的可解释性，即聚焦到时空维度上的特征持续演化可解释性)
    - 人能理解的特征提取语义映射机制
    - 高维的特征分布表征方法
    - 特征分布的长距离时空关联描绘与度量方法
    - 特征提取及其分布与决策度量模型的关系
- 从数据、模型到决策，同样的训练数据和同样的网络模型，为什么训练不同次数或者不同分布会得到不同结果? (DL网络 模型的特征提取完备性与特征转换误差积累控制的可解释性)
    - 特征提取的完备性
    - 特征分布的合理性
    - 特征转换误差的可控制性
    - 基于注意力机制的特征转换标识与监控机制
    - 特征持续演化与与决策度量模型的关系


张长水 构造一个每一个神经元，每一个神经隐层与决策过程关联的历程。
用例子，手写识别阿拉伯数字的典型数据。选择一个稍为复杂的例子来研究。从上面四个可解释的动态场景下，既有多任务学习场景，又有对于动态特征非静态物理特征下，完成结构，特征，模型组合可解释能有所体现。
通过多任务连续学习，找到模型结构，结构可解释的哪些理论可以放到应用场景里去。也能找到对应神经元与对应特征，找出指向的特征。类似特征神经元如何聚到一起，神经元聚簇是出于什么关系，关系复杂的对于模型有什么关系。


下一次需要形成共同写作纲领，四个理论方法+应用场景
采用李青老师形式，什么问题，什么背景，挑战是什么，用什么技术路线，形成技术闭环。
ppt包括任务背景，针对问题，挑战，抽取出来的理论方法要点，理论要点以图，技术线路，思维的方式体现出来。

动态处理，目标跟踪等